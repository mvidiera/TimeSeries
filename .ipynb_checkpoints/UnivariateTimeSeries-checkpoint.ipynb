{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop LSTM Models For Univariate Time Series Forecasting\n",
    "\n",
    "\n",
    "Univariate time series is the time series that consists of single observations recorded sequentially over equal time increments\n",
    "\n",
    "There is no output independant/dependant features. Each entry on my dataset depends on previous entries of my dataset\n",
    "\n",
    "ex: \n",
    "1. Sales on each day\n",
    "2. stock price on each day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem statement: consider sales on 9 days, predicts the sales on next 10 days\n",
    "\n",
    "# univariate lstm example\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing independent and dependent features\n",
    "def prepare_data(timeseries_data, n_features): #arg: timeseries and stepsize=3 i.e, x= 1st, 2nd, 3rd -> y= 4th\n",
    "\tX, y =[],[] #create X and y list \n",
    "    \n",
    "\tfor i in range(len(timeseries_data)): #i=0 to 10\n",
    "\t\t# find the end of this pattern: to find end. initially end= 3, 4th element\n",
    "\t\tend_ix = i + n_features #end=3\n",
    "\t\t# check if we are beyond the sequence: now check if end reached 9th pos(last element), if yes then break\n",
    "\t\tif end_ix > len(timeseries_data)-1:\n",
    "\t\t\tbreak #if end hasnt reached 9th index then do \n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = timeseries_data[i:end_ix], timeseries_data[end_ix]\n",
    "\t\tX.append(seq_x)#x=[0:3] upper bound isnt considered = 110,125, 133\n",
    "\t\ty.append(seq_y)#y=[3] = 146\n",
    "\treturn np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "timeseries_data = [110, 125, 133, 146, 158, 172, 187, 196, 210] # need not to be in ascending series\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# split into samples: preparing dependant and independant variables\n",
    "X, y = prepare_data(timeseries_data, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[110 125 133]\n",
      " [125 133 146]\n",
      " [133 146 158]\n",
      " [146 158 172]\n",
      " [158 172 187]\n",
      " [172 187 196]]\n",
      "[146 158 172 187 196 210]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X),print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # 3 features by which 6 records are created \n",
    "#6 is number of records. 3 is timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before feeding timesteps/input to lstm, we always have to reshape the data int0 3D\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "\n",
    "n_features1 = 1\n",
    "X = X.reshape(X.shape[0], X.shape[1], n_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[110],\n",
       "        [125],\n",
       "        [133]],\n",
       "\n",
       "       [[125],\n",
       "        [133],\n",
       "        [146]],\n",
       "\n",
       "       [[133],\n",
       "        [146],\n",
       "        [158]],\n",
       "\n",
       "       [[146],\n",
       "        [158],\n",
       "        [172]],\n",
       "\n",
       "       [[158],\n",
       "        [172],\n",
       "        [187]],\n",
       "\n",
       "       [[172],\n",
       "        [187],\n",
       "        [196]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 06:06:53.728202: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 3s 3s/step - loss: 32891.7500\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 32745.0527\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 32610.0312\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 32489.4746\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 32381.2344\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 32281.2129\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 32182.0234\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 32077.0781\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 31956.5488\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 31798.1191\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 31575.7344\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 31279.9590\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 30915.3906\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 30506.3223\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 30083.8496\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 29642.2285\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 29187.3809\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 28717.4746\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 28230.3184\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 27723.4688\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 27194.0684\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 26638.6230\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 26052.6875\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 25429.0156\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 24749.5645\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 23998.0684\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 23167.1094\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 22283.1465\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 21302.6250\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 20036.3809\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 18286.0898\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 16285.1377\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14400.4424\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 12611.7393\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 10890.6846\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9229.3359\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7571.6929\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5871.8047\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4198.3276\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2709.2852\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1359.1455\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 341.3313\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 41.7645\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 923.7038\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1503.0210\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1359.0543\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 912.1850\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 535.3625\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 280.3728\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 135.3092\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 60.7674\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 24.9384\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 11.6926\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 12.3689\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 21.1316\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.1302\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 44.0283\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 50.9658\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 53.2370\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 51.5575\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 47.0835\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 40.9495\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 34.1828\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 27.7016\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 22.2739\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.4535\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 16.5142\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 16.4148\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.8013\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 20.0687\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 22.4932\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 24.4048\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 25.3459\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 25.1636\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 24.0057\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 22.2307\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.2753\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.5307\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.2598\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.5689\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 16.4216\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 16.6814\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 17.1616\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.6725\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.0576\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.2150\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 18.1057\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 17.7504\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 17.2155\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 16.5948\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 15.9888\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 15.4837\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 15.1349\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 14.9572\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 14.9238\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 14.9745\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 15.0326\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 15.0253\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 14.9022\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 14.6456\n",
      "Epoch 101/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 14.2684\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 13.8010\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.2724\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 12.6931\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 12.0481\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.3105\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10.5060\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.9488\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.5039\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.6100\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.0410\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.5937\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.9959\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 6.6082\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.1657\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.6692\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.3598\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.0491\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.8752\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.6936\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.5863\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.4971\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.4301\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.3829\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.3542\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.3052\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.2691\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.2385\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.1996\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.1554\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.1093\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.0619\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0125\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9594\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9038\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.8463\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.8016\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7605\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7110\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.6742\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.6369\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.5994\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.5693\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.5514\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.5391\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.4723\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.5655\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.4392\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.3502\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.3613\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.3398\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.2946\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.2787\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.2283\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.1655\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.1739\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.1456\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.0855\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.0589\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.0382\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.0283\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.0135\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.9927\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.9507\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.9168\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.8933\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.9063\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.9017\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.8932\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.8142\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.7933\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.8035\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.7738\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.7236\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.7370\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.7577\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.7057\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.6533\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6487\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.6268\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6100\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.6006\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.5866\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.5612\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.5384\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.5266\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.5161\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.5050\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.4861\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.4830\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.4779\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4604\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4322\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.4094\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.4220\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3896\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.3824\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3886\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3893\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3783\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3588\n",
      "Epoch 202/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3309\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3089\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.3475\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3746\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2936\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3306\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3218\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3069\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2805\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2763\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.2923\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2725\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.2239\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1939\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1749\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.1494\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.1949\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.2203\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 2.1571\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.1019\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.1059\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1276\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.1739\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1017\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0480\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.0200\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0332\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.0191\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9904\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.9468\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.9540\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.0051\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0015\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.8842\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.8810\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.9214\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8824\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8083\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8476\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.8306\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7544\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7076\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7346\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7271\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6086\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6495\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.8108\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.5828\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4977\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.5810\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4693\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4152\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3470\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3810\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3705\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3002\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.2037\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1277\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1104\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0806\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9493\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9355\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.9565\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7673\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9608\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0775\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0589\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0300\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0330\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0969\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3774\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9734\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4078\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8211\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6366\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6049\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6209\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6927\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4928\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6473\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5888\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3696\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7160\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5193\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4084\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7506\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3432\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4579\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4522\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2754\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3758\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3231\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2641\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3323\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2483\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2808\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2995\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2285\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe49cb4ca00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# define model\n",
    "#create sequential layer\n",
    "model = Sequential()\n",
    "#Input layer with 50 neurons. Relu AF, ***input shape= stepsize and features which we gave at last to convert into 3 D\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features1)))\n",
    "#Hidden layer\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "#Op lyer with 1 neuron\n",
    "model.add(Dense(1))\n",
    "#compiling: calculate loss, reduce model with adam\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=300, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting For the next 10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[222.39233]\n",
      "1 day input [196.         210.         222.39233398]\n",
      "1 day output [[233.6269]]\n",
      "2 day input [210.         222.39233398 233.62690735]\n",
      "2 day output [[247.79518]]\n",
      "3 day input [222.39233 233.6269  247.79518]\n",
      "3 day output [[261.32437]]\n",
      "4 day input [233.6269  247.79518 261.32437]\n",
      "4 day output [[275.13245]]\n",
      "5 day input [247.79518 261.32437 275.13245]\n",
      "5 day output [[290.91498]]\n",
      "6 day input [261.32437 275.13245 290.91498]\n",
      "6 day output [[306.79245]]\n",
      "7 day input [275.13245 290.91498 306.79245]\n",
      "7 day output [[323.62488]]\n",
      "8 day input [290.91498 306.79245 323.62488]\n",
      "8 day output [[342.07324]]\n",
      "9 day input [306.79245 323.62488 342.07324]\n",
      "9 day output [[361.20755]]\n",
      "[222.39233, 233.6269, 247.79518, 261.32437, 275.13245, 290.91498, 306.79245, 323.62488, 342.07324, 361.20755]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction for next 10 days\n",
    "\n",
    "#take data from previous 3 days data \n",
    "x_input = np.array([187, 196, 210])\n",
    "#this 3 days data is stored in temp\n",
    "temp_input=list(x_input)\n",
    "#create new list called op\n",
    "lst_output=[]\n",
    "i=0\n",
    "\n",
    "#until i<10 do \n",
    "\n",
    "while(i<10):\n",
    "    \n",
    "    if(len(temp_input)>3):\n",
    "        x_input=np.array(temp_input[1:])\n",
    "        print(\"{} day input {}\".format(i,x_input))\n",
    "        #print(x_input)\n",
    "        x_input = x_input.reshape((1, n_steps, n_features1))\n",
    "        #print(x_input)\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        print(\"{} day output {}\".format(i,yhat))\n",
    "        temp_input.append(yhat[0][0])\n",
    "        temp_input=temp_input[1:]\n",
    "        #print(temp_input)\n",
    "        lst_output.append(yhat[0][0])\n",
    "        i=i+1\n",
    "    else:\n",
    "        x_input = x_input.reshape((1, n_steps, n_features1))\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        print(yhat[0])\n",
    "        temp_input.append(yhat[0][0])\n",
    "        lst_output.append(yhat[0][0])\n",
    "        i=i+1\n",
    "    \n",
    "\n",
    "print(lst_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[110, 125, 133, 146, 158, 172, 187, 196, 210]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timeseries_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[222.39233,\n",
       " 233.6269,\n",
       " 247.79518,\n",
       " 261.32437,\n",
       " 275.13245,\n",
       " 290.91498,\n",
       " 306.79245,\n",
       " 323.62488,\n",
       " 342.07324,\n",
       " 361.20755]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[170, 180, 190]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaing The Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_new=np.arange(1,10) # I have data from 1st till 9th day\n",
    "day_pred=np.arange(10,20)#predicted data from 10th till 20th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe4a5c8a880>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(day_new,timeseries_data)\n",
    "plt.plot(day_pred,lst_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
